{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2271432f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb36ccf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(537, 391), (538, 391), (539, 391), (536, 392), (537, 392), (538, 392), (539, 392), (535, 393), (536, 393), (537, 393), (538, 393), (539, 393), (534, 394), (535, 394), (536, 394), (537, 394), (538, 394), (534, 395), (535, 395), (536, 395), (537, 395), (538, 395), (535, 396), (536, 396), (537, 396), (701, 453), (702, 453), (703, 453), (700, 454), (701, 454), (702, 454), (703, 454), (704, 454), (700, 455), (701, 455), (702, 455), (703, 455), (699, 456), (700, 456), (701, 456), (702, 456), (703, 456), (699, 457), (700, 457), (701, 457), (702, 457), (699, 458), (700, 458), (701, 458), (700, 459), (701, 459), (514, 479), (515, 479), (516, 479), (378, 480), (512, 480), (513, 480), (514, 480), (515, 480), (516, 480), (517, 480), (378, 481), (512, 481), (513, 481), (514, 481), (515, 481), (516, 481), (517, 481), (518, 481), (511, 482), (512, 482), (513, 482), (514, 482), (515, 482), (516, 482), (517, 482), (518, 482), (511, 483), (512, 483), (513, 483), (514, 483), (515, 483), (516, 483), (517, 483), (510, 484), (511, 484), (512, 484), (513, 484), (514, 484), (515, 484), (516, 484), (517, 484), (510, 485), (511, 485), (512, 485), (513, 485), (514, 485), (515, 485), (516, 485), (510, 486), (511, 486), (512, 486), (513, 486), (514, 486), (515, 486), (516, 486), (512, 487), (513, 487), (638, 490), (639, 490), (640, 490), (637, 491), (638, 491), (639, 491), (640, 491), (641, 491), (635, 492), (636, 492), (637, 492), (638, 492), (639, 492), (640, 492), (641, 492), (642, 492), (635, 493), (636, 493), (637, 493), (638, 493), (639, 493), (640, 493), (641, 493), (642, 493), (635, 494), (636, 494), (637, 494), (638, 494), (639, 494), (640, 494), (641, 494), (634, 495), (635, 495), (636, 495), (637, 495), (638, 495), (639, 495), (640, 495), (634, 496), (635, 496), (636, 496), (637, 496), (638, 496), (634, 497), (635, 497), (636, 497), (302, 522), (303, 522), (304, 522), (305, 522), (306, 522), (301, 523), (302, 523), (303, 523), (304, 523), (305, 523), (306, 523), (307, 523), (300, 524), (301, 524), (302, 524), (303, 524), (304, 524), (305, 524), (306, 524), (307, 524), (300, 525), (301, 525), (302, 525), (303, 525), (304, 525), (305, 525), (306, 525), (307, 525), (300, 526), (301, 526), (302, 526), (303, 526), (304, 526), (305, 526), (306, 526), (300, 527), (301, 527), (302, 527), (303, 527), (304, 527), (559, 538), (560, 538), (561, 538), (559, 539), (560, 539), (561, 539), (558, 540), (559, 540), (560, 540), (561, 540), (428, 541), (429, 541), (558, 541), (559, 541), (560, 541), (428, 542), (429, 542), (430, 542), (428, 543), (429, 543), (430, 543), (429, 544), (218, 568), (219, 568), (218, 569), (472, 598), (473, 598), (474, 598), (471, 599), (472, 599), (473, 599), (474, 599), (475, 599), (471, 600), (472, 600), (473, 600), (474, 600), (475, 600), (476, 600), (477, 600), (471, 601), (472, 601), (473, 601), (474, 601), (475, 601), (476, 601), (477, 601), (474, 602), (475, 602), (265, 628), (266, 628), (267, 628), (268, 628), (269, 628), (263, 629), (264, 629), (265, 629), (266, 629), (267, 629), (268, 629), (269, 629), (262, 630), (263, 630), (264, 630), (265, 630), (266, 630), (267, 630), (268, 630), (269, 630), (261, 631), (262, 631), (263, 631), (264, 631), (265, 631), (266, 631), (267, 631), (268, 631), (269, 631), (260, 632), (261, 632), (262, 632), (263, 632), (264, 632), (265, 632), (266, 632), (267, 632), (268, 632), (269, 632), (260, 633), (261, 633), (262, 633), (263, 633), (264, 633), (265, 633), (266, 633), (267, 633), (268, 633), (260, 634), (261, 634), (262, 634), (263, 634), (264, 634), (265, 634), (266, 634), (267, 634), (260, 635), (261, 635), (262, 635), (263, 635), (264, 635), (265, 635), (266, 635), (259, 636), (260, 636), (261, 636), (262, 636), (263, 636), (264, 636), (260, 637), (261, 637), (262, 637), (400, 640), (399, 641), (400, 641), (401, 641), (398, 642), (399, 642), (400, 642), (401, 642), (397, 643), (398, 643), (399, 643), (400, 643), (401, 643), (397, 644), (398, 644), (399, 644), (400, 644), (401, 644), (397, 645), (398, 645), (399, 645), (400, 645), (401, 645), (397, 646), (398, 646), (399, 646), (400, 646), (397, 647), (398, 647), (399, 647), (397, 648), (398, 648)]\n",
      "Found needle.\n"
     ]
    }
   ],
   "source": [
    "# Can use IMREAD flags to do different pre-processing of image files,\n",
    "# like making them grayscale or reducing the size.\n",
    "# https://docs.opencv.org/4.2.0/d4/da8/group__imgcodecs.html\n",
    "haystack_img = cv.imread('Images/albion_farm.jpg', cv.IMREAD_UNCHANGED)\n",
    "needle_img = cv.imread('Images/albion_cabbage.jpg', cv.IMREAD_UNCHANGED)\n",
    "\n",
    "# There are 6 comparison methods to choose from:\n",
    "# TM_CCOEFF, TM_CCOEFF_NORMED, TM_CCORR, TM_CCORR_NORMED, TM_SQDIFF, TM_SQDIFF_NORMED\n",
    "\n",
    "# You can see the differences at a glance here:\n",
    "# https://docs.opencv.org/master/d4/dc6/tutorial_py_template_matching.html\n",
    "\n",
    "# Note that the values are inverted for TM_SQDIFF and TM_SQDIFF_NORMED\n",
    "result = cv.matchTemplate(haystack_img, needle_img, cv.TM_SQDIFF_NORMED)\n",
    "\n",
    "# I've inverted the threshold and where comparison to work with TM_SQDIFF_NORMED\n",
    "threshold = 0.17\n",
    "\n",
    "# The np.where() return value will look like this:\n",
    "# (array([482, 483, 483, 483, 484], dtype=int32), array([514, 513, 514, 515, 514], dtype=int32))\n",
    "locations = np.where(result <= threshold)\n",
    "\n",
    "# We can zip those up into a list of (x, y) position tuples\n",
    "locations = list(zip(*locations[::-1]))\n",
    "print(locations)\n",
    "\n",
    "if locations:\n",
    "    print('Found needle.')\n",
    "\n",
    "    needle_w = needle_img.shape[1]\n",
    "    needle_h = needle_img.shape[0]\n",
    "    line_color = (0, 255, 0)\n",
    "    line_type = cv.LINE_4\n",
    "\n",
    "    # Loop over all the locations and draw their rectangle\n",
    "    for loc in locations:\n",
    "        # Determine the box positions\n",
    "        top_left = loc\n",
    "        bottom_right = (top_left[0] + needle_w, top_left[1] + needle_h)\n",
    "        # Draw the box\n",
    "        cv.rectangle(haystack_img, top_left, bottom_right, line_color, line_type)\n",
    "\n",
    "    cv.imshow('Matches', haystack_img)\n",
    "    cv.waitKey()\n",
    "    #cv.imwrite('result.jpg', haystack_img)\n",
    "\n",
    "else:\n",
    "    print('Needle not found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd55d872",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
